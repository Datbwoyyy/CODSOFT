{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b4e54dd1a8a43708285d0b704820bec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_983e80bcf92046e38da1608a3b10d7ea",
              "IPY_MODEL_761cd3725f5844d4b61233042600eeed",
              "IPY_MODEL_ba5d8089e0a748e0ae7427b10244553e"
            ],
            "layout": "IPY_MODEL_4304404d4754442c9e0d6469916cba1c"
          }
        },
        "983e80bcf92046e38da1608a3b10d7ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef5169f39e5c4c1da233505f2dc49d31",
            "placeholder": "​",
            "style": "IPY_MODEL_3505f869d95343a48db18e4106c6fa96",
            "value": "Dl Completed...: 100%"
          }
        },
        "761cd3725f5844d4b61233042600eeed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33406d9b83fb4275af6b069747ed818f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e418c5e4b334488b98eed6a64808032f",
            "value": 1
          }
        },
        "ba5d8089e0a748e0ae7427b10244553e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e98e73422db4a4ea3c73d684afce421",
            "placeholder": "​",
            "style": "IPY_MODEL_bb2d4a10c73b4d298486e6aec8b07cb4",
            "value": " 1/1 [03:18&lt;00:00, 152.01s/ url]"
          }
        },
        "4304404d4754442c9e0d6469916cba1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef5169f39e5c4c1da233505f2dc49d31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3505f869d95343a48db18e4106c6fa96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33406d9b83fb4275af6b069747ed818f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e418c5e4b334488b98eed6a64808032f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e98e73422db4a4ea3c73d684afce421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb2d4a10c73b4d298486e6aec8b07cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "836d2a4c632944a5adfbe03c3bdcab51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a453fb25b0994b08a3b48cccf0fea1c4",
              "IPY_MODEL_c61ba123246d4c77887f0cd97f9d6992",
              "IPY_MODEL_342c7e6e2ea542e0b72b5059f95ca813"
            ],
            "layout": "IPY_MODEL_516efaf01a04413686a8a24a3f6013a2"
          }
        },
        "a453fb25b0994b08a3b48cccf0fea1c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bc4ad6d049648ff8e0ec2e5244933f7",
            "placeholder": "​",
            "style": "IPY_MODEL_630e51927d364432a1c39d82b8594697",
            "value": "Dl Size...: 100%"
          }
        },
        "c61ba123246d4c77887f0cd97f9d6992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36bb74d4e2dc45e0a739209a39b28e7a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b97f846742c846ecb9fde98a1a645803",
            "value": 1
          }
        },
        "342c7e6e2ea542e0b72b5059f95ca813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c4b18a2fd584a249ba75e6c1c132eed",
            "placeholder": "​",
            "style": "IPY_MODEL_414a81e4831d43dd84ad07f83c37be6c",
            "value": " 172/172 [03:18&lt;00:00,  1.01 MiB/s]"
          }
        },
        "516efaf01a04413686a8a24a3f6013a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bc4ad6d049648ff8e0ec2e5244933f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "630e51927d364432a1c39d82b8594697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36bb74d4e2dc45e0a739209a39b28e7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b97f846742c846ecb9fde98a1a645803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c4b18a2fd584a249ba75e6c1c132eed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "414a81e4831d43dd84ad07f83c37be6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52efdf3dba4e4382b8ba2c70a3006214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2bce345a1e14831a159b014fb3ee6c5",
              "IPY_MODEL_66220ac082a44679ae2e68681ade102d",
              "IPY_MODEL_dded67d2047047d1aecdfc012173dcb4"
            ],
            "layout": "IPY_MODEL_3dd158550fb041a0878e9cb6a3f59897"
          }
        },
        "b2bce345a1e14831a159b014fb3ee6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_253044b6c428408ba928a9fdd9aff891",
            "placeholder": "​",
            "style": "IPY_MODEL_d0b21a430af74c7b8e841df391c2adb2",
            "value": "Extraction completed...: 100%"
          }
        },
        "66220ac082a44679ae2e68681ade102d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24451ca4576943ba9c465633ec672169",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c060a773bf14b76aae730cb7cef9a44",
            "value": 0
          }
        },
        "dded67d2047047d1aecdfc012173dcb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a238d0b5dff64b7dbb9d7ed1fadef4b9",
            "placeholder": "​",
            "style": "IPY_MODEL_4e01d0afef094f1cbd372e81a068f334",
            "value": " 13233/13233 [03:18&lt;00:00, 616.28 file/s]"
          }
        },
        "3dd158550fb041a0878e9cb6a3f59897": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "253044b6c428408ba928a9fdd9aff891": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0b21a430af74c7b8e841df391c2adb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24451ca4576943ba9c465633ec672169": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1c060a773bf14b76aae730cb7cef9a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a238d0b5dff64b7dbb9d7ed1fadef4b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e01d0afef094f1cbd372e81a068f334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### REAL TIME FACE DETECTION AND FACE RECOGNITION\n",
        "\n",
        "**Objective:** Develop a facial recognition system using the LFW dataset to verify if a detected face matches a specific individual. The system integrates a \"door animation\" that opens for recognized individuals and closes otherwise.\n",
        "\n",
        "**Key Highlights:**\n",
        "\n",
        "* Dataset Streaming:\n",
        "\n",
        "Use TensorFlow Datasets (TFDS) to stream the Labeled Faces in the Wild (LFW) dataset without downloading.\n",
        "Dynamically preprocess images (resize and normalize).\n",
        "\n",
        "* Face Verification:\n",
        "\n",
        "Create positive and negative pairs for training using the LFW dataset.\n",
        "Train a Siamese Network to measure similarity between faces.\n",
        "\n",
        "* Door Animation:\n",
        "\n",
        "Use OpenCV to simulate a real-world response with an \"Open Door\" or \"Close Door\" animation based on recognition results.\n",
        "\n",
        "* Dynamic and Scalable:\n",
        "\n",
        "Efficient memory usage by streaming data in batches.\n",
        "Suitable for real-time face verification applications.\n",
        "\n",
        "    This exercise combines machine learning, computer vision, and real-world applications in an engaging and interactive way. Perfect for beginners exploring face verification or for showcasing a practical AI project!"
      ],
      "metadata": {
        "id": "teOysLtSyYUE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4Oh9b2dyTmM",
        "outputId": "9b0d080d-5901-4e02-b506-025ac698ab42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (4.9.7)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (8.1.8)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.1.8)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (4.2.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (17.0.0)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.1.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.13.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (4.67.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.6.0)\n",
            "Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (1.11.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (3.21.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.66.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "## Installing Required Libraries\n",
        "!pip install tensorflow tensorflow-datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stream The LFW Dataset"
      ],
      "metadata": {
        "id": "-llF1PlH0FjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow-datasets\n"
      ],
      "metadata": {
        "id": "DE1ByQmzuKkb",
        "outputId": "f91ddd1e-4ae4-4ddb-a490-db6be25ad64e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (4.9.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (8.1.8)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.1.8)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (4.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.26.4)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (4.25.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (5.9.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (17.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.32.3)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.1.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.13.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (2.5.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (4.67.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (1.17.0)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets) (0.6.0)\n",
            "Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (1.11.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (4.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2024.12.14)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow-datasets) (1.17.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.66.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a function to process the dataset\n",
        "def preprocess_image(features):\n",
        "    image = tf.image.convert_image_dtype(features['image'], tf.float32)  # Normalize to [0, 1]\n",
        "    label = features['label']\n",
        "    return image, label\n",
        "\n",
        "# Load the dataset directly from GCS\n",
        "train_dataset = tfds.load(\"lfw\", split=\"train\", as_supervised=False, shuffle_files=True)\n",
        "\n",
        "# Apply preprocessing\n",
        "train_dataset = train_dataset.map(preprocess_image).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Display dataset info\n",
        "dataset_info = tfds.builder(\"lfw\").info\n",
        "print(dataset_info)\n",
        "\n",
        "# Function to visualize images\n",
        "def visualize_images(dataset, num_images=5):\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    image_count = 0\n",
        "\n",
        "    for batch in dataset:  # Each batch contains (images, labels)\n",
        "        images, labels = batch  # Unpack images and labels\n",
        "        for i in range(images.shape[0]):  # Iterate over the batch\n",
        "            if image_count >= num_images:\n",
        "                break\n",
        "\n",
        "            ax = plt.subplot(1, num_images, image_count + 1)\n",
        "            plt.imshow(tf.keras.utils.array_to_img(images[i]))  # Convert single image to PIL format\n",
        "            plt.title(labels[i].numpy().decode())  # Decode label\n",
        "            plt.axis(\"off\")\n",
        "            image_count += 1\n",
        "\n",
        "        if image_count >= num_images:\n",
        "            break\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Visualize images\n",
        "visualize_images(train_dataset, num_images=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "2b4e54dd1a8a43708285d0b704820bec",
            "983e80bcf92046e38da1608a3b10d7ea",
            "761cd3725f5844d4b61233042600eeed",
            "ba5d8089e0a748e0ae7427b10244553e",
            "4304404d4754442c9e0d6469916cba1c",
            "ef5169f39e5c4c1da233505f2dc49d31",
            "3505f869d95343a48db18e4106c6fa96",
            "33406d9b83fb4275af6b069747ed818f",
            "e418c5e4b334488b98eed6a64808032f",
            "2e98e73422db4a4ea3c73d684afce421",
            "bb2d4a10c73b4d298486e6aec8b07cb4",
            "836d2a4c632944a5adfbe03c3bdcab51",
            "a453fb25b0994b08a3b48cccf0fea1c4",
            "c61ba123246d4c77887f0cd97f9d6992",
            "342c7e6e2ea542e0b72b5059f95ca813",
            "516efaf01a04413686a8a24a3f6013a2",
            "8bc4ad6d049648ff8e0ec2e5244933f7",
            "630e51927d364432a1c39d82b8594697",
            "36bb74d4e2dc45e0a739209a39b28e7a",
            "b97f846742c846ecb9fde98a1a645803",
            "8c4b18a2fd584a249ba75e6c1c132eed",
            "414a81e4831d43dd84ad07f83c37be6c",
            "52efdf3dba4e4382b8ba2c70a3006214",
            "b2bce345a1e14831a159b014fb3ee6c5",
            "66220ac082a44679ae2e68681ade102d",
            "dded67d2047047d1aecdfc012173dcb4",
            "3dd158550fb041a0878e9cb6a3f59897",
            "253044b6c428408ba928a9fdd9aff891",
            "d0b21a430af74c7b8e841df391c2adb2",
            "24451ca4576943ba9c465633ec672169",
            "1c060a773bf14b76aae730cb7cef9a44",
            "a238d0b5dff64b7dbb9d7ed1fadef4b9",
            "4e01d0afef094f1cbd372e81a068f334"
          ]
        },
        "id": "0L7mimVfz9jN",
        "outputId": "c3521641-f678-47c2-95f9-a90ca6cdcf77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 172.20 MiB (download: 172.20 MiB, generated: Unknown size, total: 172.20 MiB) to /root/tensorflow_datasets/lfw/0.1.0...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b4e54dd1a8a43708285d0b704820bec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "836d2a4c632944a5adfbe03c3bdcab51"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52efdf3dba4e4382b8ba2c70a3006214"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a function to preprocess the dataset\n",
        "def preprocess_for_inception(features):\n",
        "    image = tf.image.resize(features['image'], (299, 299))  # Resize to 299x299\n",
        "    image = tf.keras.applications.inception_v3.preprocess_input(image)  # Normalize to [-1, 1]\n",
        "    label = features['label']\n",
        "    return image, label\n",
        "\n",
        "# Load the dataset\n",
        "dataset_builder = tfds.builder(\"lfw\")\n",
        "dataset_builder.download_and_prepare()\n",
        "\n",
        "# Create a train dataset\n",
        "train_dataset = dataset_builder.as_dataset(split='train', as_supervised=False)\n",
        "\n",
        "# Apply preprocessing for InceptionV3\n",
        "train_dataset = (\n",
        "    train_dataset\n",
        "    .map(preprocess_for_inception, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .batch(32)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "# Display dataset info\n",
        "print(dataset_builder.info)\n",
        "\n",
        "# Function to visualize preprocessed images\n",
        "def visualize_images(dataset, num_images=5):\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    image_count = 0\n",
        "\n",
        "    for batch in dataset:  # Each batch contains (images, labels)\n",
        "        images, labels = batch\n",
        "        for i in range(images.shape[0]):  # Iterate over the batch\n",
        "            if image_count >= num_images:\n",
        "                break\n",
        "\n",
        "            ax = plt.subplot(1, num_images, image_count + 1)\n",
        "            # Convert preprocessed image back to [0, 1] for visualization\n",
        "            display_image = (images[i] + 1.0) / 2.0  # Rescale [-1, 1] to [0, 1]\n",
        "            plt.imshow(tf.keras.utils.array_to_img(display_image))\n",
        "            plt.title(labels[i].numpy().decode(\"utf-8\"))\n",
        "            plt.axis(\"off\")\n",
        "            image_count += 1\n",
        "\n",
        "        if image_count >= num_images:\n",
        "            break\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Visualize preprocessed images\n",
        "visualize_images(train_dataset, num_images=5)\n"
      ],
      "metadata": {
        "id": "Wn1M3JcMNL8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cropping Faces and Preparing Data for Transfer Learning"
      ],
      "metadata": {
        "id": "byFgfV5C1cwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the Haar Cascade\n",
        "haar_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Load the LFW dataset\n",
        "lfw_dataset = tfds.load('lfw', split='train', as_supervised=False)\n",
        "\n",
        "# Function to process and detect faces\n",
        "def detect_faces_from_lfw(sample):\n",
        "    image = sample['image'].numpy()  # Get the image as a NumPy array\n",
        "    label = sample['label'].numpy().decode()  # Decode the label\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Detect faces\n",
        "    faces = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    # Draw rectangles around detected faces\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "\n",
        "    # Display the image with detections\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"Label: {label}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# Test the function with the first few images\n",
        "for i, sample in enumerate(lfw_dataset.take(5)):\n",
        "    detect_faces_from_lfw(sample)\n"
      ],
      "metadata": {
        "id": "eYYEjdmfOKf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cropped_faces = []  # To store cropped face images\n",
        "labels = []  # To store corresponding labels\n",
        "\n",
        "# Function to crop and save faces\n",
        "def crop_and_store_faces(sample):\n",
        "    image = sample['image'].numpy()\n",
        "    label = sample['label'].numpy().decode()\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Detect faces\n",
        "    faces = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    # Crop faces\n",
        "    for (x, y, w, h) in faces:\n",
        "        cropped_face = image[y:y+h, x:x+w]\n",
        "        cropped_faces.append(cropped_face)\n",
        "        labels.append(label)  # Store the label for this face\n",
        "\n",
        "# Process all images in the dataset\n",
        "for sample in lfw_dataset.take(500):  # Limiting to 500 samples for demonstration\n",
        "    crop_and_store_faces(sample)\n",
        "\n",
        "# Resize cropped faces to the input size required by InceptionV3 (299x299)\n",
        "cropped_faces_resized = [\n",
        "    cv2.resize(face, (299, 299)) for face in cropped_faces\n",
        "]\n",
        "\n",
        "# Normalize to [0, 1]\n",
        "cropped_faces_normalized = np.array(cropped_faces_resized) / 255.0\n",
        "\n",
        "# Encode labels into integers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    cropped_faces_normalized, encoded_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training data: {x_train.shape}, Validation data: {x_val.shape}\")\n",
        "print(f\"Number of classes: {len(label_encoder.classes_)}\")\n"
      ],
      "metadata": {
        "id": "Lcvl0NonPjnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code: Training the Recognition Model\n"
      ],
      "metadata": {
        "id": "AZ2NxA6_3K_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load InceptionV3 base model\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom layers on top\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(len(label_encoder.classes_), activation='softmax')(x)\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=10,\n",
        "    batch_size=32\n",
        ")\n"
      ],
      "metadata": {
        "id": "jAGqjNuH2Zgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Face Detection Using OpenCV\n",
        "1. Load the Haar Cascade\n"
      ],
      "metadata": {
        "id": "BZs3s9NZ6URc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze some layers of the base model\n",
        "for layer in base_model.layers[-30:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Recompile with a lower learning rate\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fine-tune the model\n",
        "fine_tune_history = model.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_val, y_val),\n",
        "    epochs=5,\n",
        "    batch_size=32\n",
        ")\n"
      ],
      "metadata": {
        "id": "24eMCXfa5w50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('face_recognition_model.keras')\n",
        "\n",
        "# Evaluate on the validation set\n",
        "val_loss, val_acc = model.evaluate(x_val, y_val)\n",
        "print(f\"Validation Accuracy: {val_acc:.2f}\")\n"
      ],
      "metadata": {
        "id": "ATKtF-V67wh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load Haar cascade\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Load trained model\n",
        "model = tf.keras.models.load_model('face_recognition_model.keras')\n",
        "\n",
        "# Class labels\n",
        "class_names = ['Barack Obama', 'George Bush', 'Other']\n"
      ],
      "metadata": {
        "id": "gtoMjOotQwgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "id": "db1Rp1atrt5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw\n",
        "import streamlit as st\n",
        "\n",
        "def draw_door(opened):\n",
        "    img = Image.new(\"RGB\", (500, 300), \"white\")\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    # Door frame\n",
        "    draw.rectangle([50, 50, 450, 250], outline=\"black\", width=5)\n",
        "\n",
        "    if opened:\n",
        "        # Door open\n",
        "        draw.rectangle([300, 50, 450, 250], fill=\"white\")\n",
        "        text = \"Door Open\"\n",
        "    else:\n",
        "        # Door closed\n",
        "        draw.rectangle([50, 50, 450, 250], fill=\"brown\")\n",
        "        text = \"Door Closed\"\n",
        "\n",
        "    draw.text((200, 270), text, fill=\"black\")\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "yrXaHsnQQ0-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the app code as a string\n",
        "app_code = '''\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load Haar cascade\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Load trained model\n",
        "model = tf.keras.models.load_model('face_recognition_model.keras')\n",
        "\n",
        "# Class labels\n",
        "class_names = ['Barack Obama', 'George Bush', 'Other']\n",
        "\n",
        "# Door animation\n",
        "def draw_door(opened):\n",
        "    from PIL import Image, ImageDraw\n",
        "    img = Image.new(\"RGB\", (500, 300), \"white\")\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    # Door frame\n",
        "    draw.rectangle([50, 50, 450, 250], outline=\"black\", width=5)\n",
        "\n",
        "    if opened:\n",
        "        # Door open\n",
        "        draw.rectangle([300, 50, 450, 250], fill=\"white\")\n",
        "        text = \"Door Open\"\n",
        "    else:\n",
        "        # Door closed\n",
        "        draw.rectangle([50, 50, 450, 250], fill=\"brown\")\n",
        "        text = \"Door Closed\"\n",
        "\n",
        "    draw.text((200, 270), text, fill=\"black\")\n",
        "    return img\n",
        "\n",
        "st.title(\"Face Recognition Door System\")\n",
        "\n",
        "# Upload an image\n",
        "uploaded_file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file:\n",
        "    # Read image\n",
        "    image = np.array(Image.open(uploaded_file))\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "        # Crop and preprocess face\n",
        "        face = image[y:y + h, x:x + w]\n",
        "        face = cv2.resize(face, (299, 299))  # Inception V3 input size\n",
        "        face = np.expand_dims(face, axis=0) / 255.0\n",
        "\n",
        "        # Predict\n",
        "        predictions = model.predict(face)\n",
        "        predicted_label = class_names[np.argmax(predictions)]\n",
        "\n",
        "        # Draw face box\n",
        "        cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "        cv2.putText(image, predicted_label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
        "\n",
        "    # Door animation\n",
        "    if predicted_label in [\"Barack Obama\", \"George Bush\"]:\n",
        "        st.image(draw_door(opened=True))\n",
        "    else:\n",
        "        st.image(draw_door(opened=False))\n",
        "\n",
        "    # Display image with annotations\n",
        "    st.image(image, caption=\"Processed Image\", use_column_width=True)\n",
        "'''\n",
        "\n",
        "# Save the app code to a file\n",
        "with open(\"app.py\", \"w\") as file:\n",
        "    file.write(app_code)\n"
      ],
      "metadata": {
        "id": "vDbfo_GNRFHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of required libraries\n",
        "requirements = \"\"\"\n",
        "streamlit\n",
        "tensorflow\n",
        "opencv-python\n",
        "pillow\n",
        "numpy\n",
        "\"\"\"\n",
        "\n",
        "# Write to requirements.txt\n",
        "with open(\"requirements.txt\", \"w\") as file:\n",
        "    file.write(requirements)\n",
        "\n",
        "print(\"requirements.txt has been created.\")\n"
      ],
      "metadata": {
        "id": "Hx41tUwNUxcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Academic Torrents\n",
        "!pip install academictorrents\n",
        "\n",
        "import academictorrents as at\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Directory to store the downloaded dataset\n",
        "dataset_dir = \"./yale_faces\"\n",
        "\n",
        "# Ensure the directory exists\n",
        "if not os.path.exists(dataset_dir):\n",
        "    os.makedirs(dataset_dir)\n",
        "\n",
        "# Torrent hash for the Extended Yale Face Database B\n",
        "torrent_hash = \"06e479f338b56fa5948c40287b66f68236a14612\"\n",
        "\n",
        "# Download the dataset\n",
        "print(\"Downloading the dataset...\")\n",
        "dataset_path = at.get(torrent_hash, dataset_dir)\n",
        "print(f\"Dataset downloaded to: {dataset_path}\")\n",
        "\n",
        "# Extract the dataset\n",
        "if not os.path.exists(\"./CroppedYale\"):\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(dataset_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(\"./\")\n",
        "    print(\"Extraction complete!\")\n",
        "\n",
        "# Confirm extracted content\n",
        "print(\"Content extracted. Listing files...\")\n",
        "!ls -lh ./CroppedYale\n"
      ],
      "metadata": {
        "id": "6ro5nI7JRvTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "# Directory to save the dataset\n",
        "dataset_dir = \"/content/WIDER_FACE\"\n",
        "os.makedirs(dataset_dir, exist_ok=True)\n",
        "\n",
        "def download_file(url, output_path, expected_size=None):\n",
        "    \"\"\"Download a file and verify its size.\"\"\"\n",
        "    if os.path.exists(output_path):\n",
        "        print(f\"File already exists: {output_path}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Downloading {url}...\")\n",
        "    with requests.get(url, stream=True) as response:\n",
        "        response.raise_for_status()  # Raise an error for failed downloads\n",
        "        with open(output_path, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=1024):\n",
        "                f.write(chunk)\n",
        "    print(f\"Download complete: {output_path}\")\n",
        "\n",
        "    # Check file size if expected_size is provided\n",
        "    if expected_size and os.path.getsize(output_path) != expected_size:\n",
        "        raise ValueError(f\"Downloaded file size does not match the expected size: {expected_size} bytes\")\n",
        "\n",
        "def download_and_unzip(url, output_dir, expected_size=None):\n",
        "    \"\"\"Download and unzip a file from the given URL.\"\"\"\n",
        "    filename = os.path.join(output_dir, url.split(\"/\")[-1])\n",
        "    extracted_dir = filename.replace(\".zip\", \"\")\n",
        "\n",
        "    # Check if the file is already extracted\n",
        "    if os.path.exists(extracted_dir):\n",
        "        print(f\"Data already extracted: {extracted_dir}\")\n",
        "        return\n",
        "\n",
        "    # Download file\n",
        "    download_file(url, filename, expected_size)\n",
        "\n",
        "    # Unzip the file\n",
        "    print(f\"Extracting {filename}...\")\n",
        "    try:\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall(output_dir)\n",
        "        print(f\"Extraction complete: {extracted_dir}\")\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"Error: {filename} is not a valid zip file. Please redownload.\")\n",
        "        raise\n",
        "\n",
        "# URLs for the WIDER FACE dataset\n",
        "wider_face_train_url = \"http://shuoyang1213.me/WIDERFACE/WIDER_train.zip\"\n",
        "wider_face_val_url = \"http://shuoyang1213.me/WIDERFACE/WIDER_val.zip\"\n",
        "wider_face_anno_url = \"http://shuoyang1213.me/WIDERFACE/wider_face_split.zip\"\n",
        "\n",
        "# Expected file sizes in bytes\n",
        "expected_sizes = {\n",
        "    wider_face_train_url: 11000000000,  # ~11 GB\n",
        "    wider_face_val_url: 1400000000,    # ~1.4 GB\n",
        "    wider_face_anno_url: 20000000      # ~20 MB\n",
        "}\n",
        "\n",
        "# Download and unzip each dataset\n",
        "for url, expected_size in expected_sizes.items():\n",
        "    download_and_unzip(url, dataset_dir, expected_size)\n",
        "\n",
        "print(\"All files downloaded and extracted successfully!\")\n"
      ],
      "metadata": {
        "id": "e391eLInTZb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the ZIP file\n",
        "zip_path = \"/content/WIDER_FACE/WIDER_val.zip\"\n",
        "\n",
        "# Directory to extract the contents\n",
        "extract_dir = \"/content/WIDER_FACE/WIDER_val\"\n",
        "\n",
        "# Check if the file is a valid ZIP\n",
        "if zipfile.is_zipfile(zip_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        # Extract all contents\n",
        "        zip_ref.extractall(extract_dir)\n",
        "        print(f\"Extracted files to {extract_dir}\")\n",
        "else:\n",
        "    print(f\"The file at {zip_path} is not a valid ZIP file.\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J-FeQ-obb-Mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k4l8jSb1dg6p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}